{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import seaborn as sns\n",
    "import time\n",
    "import warnings\n",
    "import re\n",
    "from collections import Counter\n",
    "from IPython.display import FileLink, FileLinks\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import scipy.stats as stats\n",
    "from matplotlib import colors\n",
    "from matplotlib.cbook import boxplot_stats\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from tqdm import tqdm\n",
    "from tqdm import tqdm_notebook\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_score, recall_score, accuracy_score\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "random.seed(168)\n",
    "tqdm.pandas()\n",
    "sns.set(rc={\"axes.facecolor\":\"#FFF9ED\",\"figure.facecolor\":\"#FFF9ED\"})\n",
    "pallet = [\"#ea5545\", \"#f46a9b\", \"#ef9b20\", \"#edbf33\", \"#ede15b\", \"#bdcf32\", \"#87bc45\", \"#27aeef\", \"#b33dc6\"]\n",
    "pallet_prot = ['#00429d', '#2854a6', '#3e67ae', '#507bb7', '#618fbf', '#73a2c6', '#85b7ce', '#9acbd5', '#b1dfdb', '#cdf1e0', '#ffe5cc', '#ffcab9', '#ffaea5', '#fd9291', '#f4777f', '#e75d6f', '#d84360', '#c52a52', '#ae1045', '#93003a']\n",
    "base_path = '/home/lamle3105/Project_Churn/'\n",
    "# Refactor CustomerID\n",
    "def normalize_customer_number(cn):\n",
    "    if len(str(cn)) == 8 :\n",
    "        return str(cn)\n",
    "    else :\n",
    "        return (8 - len(str(cn)))*\"0\" + str(cn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load DL Feature KH\n",
    "df = pd.read_csv(\"dataset/Customer_Churn_Attributes_20231016.csv\", sep=\"\\t\", index_col=0)\n",
    "df[\"CustomerNumber\"] = df[\"CustomerNumber\"].apply(lambda x : normalize_customer_number(x))\n",
    "print(df.shape)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count occurrences of each churn category\n",
    "churn_counts = df['isChurn'].value_counts()\n",
    "\n",
    "labels = churn_counts.index\n",
    "sizes = churn_counts.values\n",
    "\n",
    "# Define colors\n",
    "colors = ['#ff9999','#66b3ff']  # Adjust as needed\n",
    "\n",
    "plt.figure(figsize=(7, 7))\n",
    "wedges, texts, autotexts = plt.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=90, colors=colors)\n",
    "\n",
    "legend_labels = [f\"{label}: {count}\" for label, count in zip(labels, sizes)]\n",
    "plt.legend(wedges, legend_labels, title=\"Churn Count\", loc=\"best\")\n",
    "\n",
    "# Add a title\n",
    "plt.title('Churn Distribution')\n",
    "\n",
    "# Display the chart\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_counts = df['Gender'].value_counts()\n",
    "\n",
    "labels = gender_counts.index\n",
    "sizes = gender_counts.values\n",
    "\n",
    "colors = ['#ff9999','#66b3ff', '#99ff99', '#ffcc99']\n",
    "\n",
    "plt.figure(figsize=(7, 7))\n",
    "wedges, texts, autotexts = plt.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=90, colors=colors)\n",
    "legend_labels = [f\"{label}: {count}\" for label, count in zip(labels, sizes)]\n",
    "plt.legend(wedges, legend_labels, title=\"Gender Count\", loc=\"best\")\n",
    "\n",
    "plt.title('Gender Distribution')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count total and unique values\n",
    "total_rows = df.shape[0]\n",
    "unique_customers = df[\"CustomerNumber\"].nunique()\n",
    "total_duplicates = df.duplicated().sum()\n",
    "duplicates_excluding_customer = df.drop(\"CustomerNumber\", axis=1).duplicated().sum()\n",
    "\n",
    "# Print summary\n",
    "print(f\"Total Rows: {total_rows}\")\n",
    "print(f\"Total Unique Customers: {unique_customers}\")\n",
    "print(f\"Total Duplicate Rows (Including Customer Number): {total_duplicates}\")\n",
    "print(f\"Total Duplicate Rows (Excluding Customer Number): {duplicates_excluding_customer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate null counts and percentages\n",
    "null_counts = df.isnull().sum()\n",
    "null_percentage = (null_counts / len(df)) * 100\n",
    "\n",
    "# Filter columns that have null values\n",
    "null_data = pd.DataFrame({\"Null Count\": null_counts, \"Null Percentage\": null_percentage})\n",
    "null_data = null_data[null_data[\"Null Count\"] > 0]  # Keep only columns with nulls\n",
    "\n",
    "# Print the result\n",
    "print(null_data.sort_values(by=\"Null Percentage\", ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_drop_na = df.dropna(subset='MembershipType')\n",
    "columns_fill_value = {\"CountNotiRead\": 0,\n",
    "                      \"CountNotiSended\": 0,\n",
    "                      \"AvgRatingPoint\": -1,\n",
    "                      \"MinRatingPoint\": -1,\n",
    "                      \"Age\": int(np.mean(df_drop_na[\"Age\"])),\n",
    "                      \"Gender\": \"UNK\",\n",
    "                      \"FirstJoinProvince\": \"UNK\",\n",
    "                      \"FirstJoinRegion\": \"UNK\",\n",
    "                      \"TotalBurnedEarn\": 0,\n",
    "                      \"AvgGcoinEarn\": 0,\n",
    "                      \"AvgBurnedEarn\": 0,\n",
    "                      \"TGS_Avartar\": 0,\n",
    "                      \"TGS_MomoRegister\": 0}\n",
    "df_fill_na = df_drop_na.fillna(value=columns_fill_value)\n",
    "mean_values = df_fill_na.groupby(\"MembershipType\")[\"TotalGcoinEarn\"].transform(\"mean\")\n",
    "df_fill_na[\"TotalGcoinEarn\"] = df_fill_na[\"TotalGcoinEarn\"].fillna(mean_values)\n",
    "df_fill_na.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_counts = df_fill_na.isnull().sum()\n",
    "null_percentage = (null_counts / len(df_fill_na)) * 100\n",
    "\n",
    "# Filter columns that have null values\n",
    "null_data = pd.DataFrame({\"Null Count\": null_counts, \"Null Percentage\": null_percentage})\n",
    "null_data = null_data[null_data[\"Null Count\"] > 0]  # Keep only columns with null values\n",
    "\n",
    "# Sort and print the result\n",
    "print(null_data.sort_values(by=\"Null Percentage\", ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fill_na.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fill_na[\"Gender\"].value_counts().to_frame().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fill_na[\"Age\"].value_counts().to_frame().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fill_na[\"MembershipType\"].value_counts().to_frame().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fill_na[\"FirstJoinProvince\"].value_counts().to_frame().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fill_na[\"FirstJoinRegion\"].value_counts().to_frame().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fill_na[\"BrandMostVisited\"].value_counts().to_frame().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fill_na[\"BrandLatestVisited\"].value_counts().to_frame().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fill_na[\"TotalGcoinEarn\"].value_counts().to_frame().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fill_na[\"CustomerNumber\"] = df_fill_na[\"CustomerNumber\"].astype(int)\n",
    "df_fill_na[\"Age\"] = df_fill_na[\"Age\"].astype(int)\n",
    "df_fill_na[\"TGS_Avartar\"] = df_fill_na[\"TGS_Avartar\"].astype(bool)\n",
    "df_fill_na[\"TGS_MomoRegister\"] = df_fill_na[\"TGS_MomoRegister\"].astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reform = df_fill_na.copy()\n",
    "\n",
    "# Check loyalty : Silver, Gold, Diamond only \n",
    "df_reform = df_reform[df_reform[\"MembershipType\"].isin([\"GPeople Silver\", \"GPeople Gold\", \"GPeople Diamond\"])]\n",
    "\n",
    "# Reformat Brand Text -> Categories  \n",
    "def normalize_brand(s):\n",
    "    s = re.sub(r'[^\\w\\s]', '', s)\n",
    "    s = re.sub(\" \", '', s)\n",
    "    s = re.sub(\"\\t\", '', s)\n",
    "    s = s.strip()\n",
    "    return s.lower()\n",
    "df_reform[\"BrandMostVisited\"] = df_reform[\"BrandMostVisited\"].apply(lambda x : normalize_brand(x))\n",
    "df_reform[\"BrandLatestVisited\"] = df_reform[\"BrandLatestVisited\"].apply(lambda x : normalize_brand(x))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
